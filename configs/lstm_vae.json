{
  "name": "lstm_vae_colab",
  "data": {
    "root": "./data",
    "train_size": 15000,
    "val_size": 1500,
    "test_size": 1500,
    "sequence_length": 20,
    "frame_size": 64,
    "num_digits": 2,
    "batch_size": 32,
    "num_workers": 4,
    "seed": 42
  },
  "model": {
    "model_type": "lstm",
    "latent_dim": 256,
    "encoder_channels": [32, 64, 128, 256],
    "decoder_channels": [256, 128, 64, 32],
    "feature_dim": 512,
    "lstm_hidden": 256,
    "lstm_layers": 2,
    "bidirectional": true,
    "in_channels": 1,
    "sequence_length": 20,
    "content_aggregation": "mean"
  },
  "training": {
    "learning_rate": 0.0003,
    "beta1": 0.9,
    "beta2": 0.999,
    "weight_decay": 1e-5,
    "beta_vae": 0.5,
    "beta_content": null,
    "beta_motion": null,
    "temporal_weight": 0.0,
    "independence_weight": 0.0,
    "recon_loss_type": "bce",
    "use_kl_annealing": true,
    "warmup_epochs": 20,
    "annealing_type": "linear",
    "kl_start_epoch": 4,
    "use_free_bits": true,
    "free_bits": 0.3,
    "num_epochs": 30,
    "gradient_clip": 5.0,
    "lr_scheduler": "cosine",
    "lr_decay": 0.98,
    "lr_min": 1e-6,
    "device": "cuda",
    "save_every": 10,
    "log_every": 50,
    "visualize_every": 15,
    "checkpoint_dir": "./checkpoints",
    "results_dir": "./results"
  }
}
